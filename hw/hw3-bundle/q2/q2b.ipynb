{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "q2b.ipynb",
      "provenance": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    }
  },
  "cells": [
    {
      "cell_type": "code",
      "metadata": {
        "id": "dERgPFyXXgto",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 343
        },
        "outputId": "6d3b4693-93f1-4a84-a581-80ae49dd4bc2"
      },
      "source": [
        "!pip install pyspark\n",
        "!pip install -U -q PyDrive\n",
        "!apt install openjdk-8-jdk-headless -qq\n",
        "import os\n",
        "os.environ[\"JAVA_HOME\"] = \"/usr/lib/jvm/java-8-openjdk-amd64\""
      ],
      "execution_count": 1,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Collecting pyspark\n",
            "\u001b[?25l  Downloading https://files.pythonhosted.org/packages/9a/5a/271c416c1c2185b6cb0151b29a91fff6fcaed80173c8584ff6d20e46b465/pyspark-2.4.5.tar.gz (217.8MB)\n",
            "\u001b[K     |████████████████████████████████| 217.8MB 60kB/s \n",
            "\u001b[?25hCollecting py4j==0.10.7\n",
            "\u001b[?25l  Downloading https://files.pythonhosted.org/packages/e3/53/c737818eb9a7dc32a7cd4f1396e787bd94200c3997c72c1dbe028587bd76/py4j-0.10.7-py2.py3-none-any.whl (197kB)\n",
            "\u001b[K     |████████████████████████████████| 204kB 44.3MB/s \n",
            "\u001b[?25hBuilding wheels for collected packages: pyspark\n",
            "  Building wheel for pyspark (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "  Created wheel for pyspark: filename=pyspark-2.4.5-py2.py3-none-any.whl size=218257927 sha256=4f97ffaeb19e1b5b7e32192297e47ab1bdd1e92f7795ed850f3b8cf8303f6eef\n",
            "  Stored in directory: /root/.cache/pip/wheels/bf/db/04/61d66a5939364e756eb1c1be4ec5bdce6e04047fc7929a3c3c\n",
            "Successfully built pyspark\n",
            "Installing collected packages: py4j, pyspark\n",
            "Successfully installed py4j-0.10.7 pyspark-2.4.5\n",
            "openjdk-8-jdk-headless is already the newest version (8u242-b08-0ubuntu3~18.04).\n",
            "The following package was automatically installed and is no longer required:\n",
            "  libnvidia-common-430\n",
            "Use 'apt autoremove' to remove it.\n",
            "0 upgraded, 0 newly installed, 0 to remove and 25 not upgraded.\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "X8W0jZqKXjCg",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "from pydrive.auth import GoogleAuth\n",
        "from pydrive.drive import GoogleDrive\n",
        "from google.colab import auth\n",
        "from oauth2client.client import GoogleCredentials\n",
        "\n",
        "# Authenticate and create the PyDrive client\n",
        "auth.authenticate_user()\n",
        "gauth = GoogleAuth()\n",
        "gauth.credentials = GoogleCredentials.get_application_default()\n",
        "drive = GoogleDrive(gauth)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "S2ExXtfUXv83",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "import pandas as pd\n",
        "import numpy as np\n",
        "import matplotlib.pyplot as plt\n",
        "%matplotlib inline\n",
        "\n",
        "import pyspark\n",
        "from pyspark.sql import *\n",
        "from pyspark.sql.types import *\n",
        "from pyspark.sql.functions import *\n",
        "from pyspark import SparkContext, SparkConf\n",
        "from pyspark.mllib.linalg.distributed import CoordinateMatrix, MatrixEntry, DenseMatrix"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "tCQK0ur5X1ES",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# create the session\n",
        "conf = SparkConf().set(\"spark.ui.port\", \"4050\")\n",
        "\n",
        "# create the context\n",
        "sc = pyspark.SparkContext(conf=conf)\n",
        "spark = SparkSession.builder.getOrCreate()"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "6stP5iUpX3HD",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "small_data = sc.textFile('graph-small.txt')\n",
        "full_data = sc.textFile('graph-full.txt')\n",
        "\n",
        "LAMBDA = 1\n",
        "NU = 1"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "6OSNbR-xX71o",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "source_dest_pair = full_data.map(lambda x: (int(x.split('\\t')[0]) - 1, int(x.split('\\t')[1]) - 1)).distinct()\n",
        "edges = source_dest_pair.map(lambda x: (x[0], x[1], 1))\n",
        "edges_transpose = source_dest_pair.map(lambda x: (x[1], x[0], 1))"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "2sFHamGiYVb3",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "L = CoordinateMatrix(edges).toBlockMatrix()\n",
        "L_transpose = CoordinateMatrix(edges_transpose).toBlockMatrix()"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "PpOiTFIKYdbQ",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "h_init = []\n",
        "\n",
        "for i in range(1000):\n",
        "  h_init.append((i, 0, 1))"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "DxslIdjkZSIe",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "h = CoordinateMatrix(sc.parallelize(h_init)).toBlockMatrix()"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "6_52mKzKZIjr",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "a = None\n",
        "\n",
        "for i in range(40):\n",
        "\n",
        "  a_new = L_transpose.multiply(h)\n",
        "  a_new_max = np.max(np.array(a_new.toLocalMatrix().toArray()))\n",
        "  a_new_max_inverse = []\n",
        "  for j in range(1000):\n",
        "    a_new_max_inverse.append((j, j, 1 / a_new_max))\n",
        "  a_new_max_inverse = CoordinateMatrix(sc.parallelize(a_new_max_inverse)).toBlockMatrix()\n",
        "  a = a_new_max_inverse.multiply(a_new)\n",
        "\n",
        "  h_new = L.multiply(a)\n",
        "  h_new_max = np.max(np.array(h_new.toLocalMatrix().toArray()))\n",
        "  h_new_max_inverse = []\n",
        "  for j in range(1000):\n",
        "    h_new_max_inverse.append((j, j, 1 / h_new_max))\n",
        "  h_new_max_inverse = CoordinateMatrix(sc.parallelize(h_new_max_inverse)).toBlockMatrix()\n",
        "  h = h_new_max_inverse.multiply(h_new)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "tscFZmqJZ4WN",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "h_numpy = np.array(h.toLocalMatrix().toArray())\n",
        "a_numpy = np.array(a.toLocalMatrix().toArray())\n",
        "h_min_args = np.argsort(h_numpy, axis = 0)[:5]\n",
        "a_min_args = np.argsort(a_numpy, axis = 0)[:5]\n",
        "h_max_args = np.argsort(-h_numpy, axis = 0)[:5]\n",
        "a_max_args = np.argsort(-a_numpy, axis = 0)[:5]"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "nyRbEXAqd2vI",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 629
        },
        "outputId": "353a28d7-e900-4af3-fc09-6a4e75fbe4ae"
      },
      "source": [
        "print(\"The 5 node ids with the highest hubbiness scores:\")\n",
        "for args in h_max_args:\n",
        "  print(\"Node id: {}, hubbiness score: {}\".format(args[0] + 1, h_numpy[args][0][0]))\n",
        "\n",
        "print(\"\\n\\n\")\n",
        "\n",
        "print(\"The 5 node ids with the lowest hubbiness scores:\")\n",
        "for args in h_min_args:\n",
        "  print(\"Node id: {}, hubbiness score: {}\".format(args[0] + 1, h_numpy[args][0][0]))\n",
        "\n",
        "print(\"\\n\\n\")\n",
        "\n",
        "print(\"The 5 node ids with the highest authority scores:\")\n",
        "for args in a_max_args:\n",
        "  print(\"Node id: {}, hubbiness score: {}\".format(args[0] + 1, a_numpy[args][0][0]))\n",
        "\n",
        "print(\"\\n\\n\")\n",
        "\n",
        "print(\"The 5 node ids with the lowest authority scores:\")\n",
        "for args in a_min_args:\n",
        "  print(\"Node id: {}, hubbiness score: {}\".format(args[0] + 1, a_numpy[args][0][0]))\n",
        "\n",
        "print(\"\\n\\n\")"
      ],
      "execution_count": 30,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "The 5 node ids with the highest hubbiness scores:\n",
            "Node id: 840, hubbiness score: 1.0\n",
            "Node id: 155, hubbiness score: 0.9499618624906543\n",
            "Node id: 234, hubbiness score: 0.8986645288972264\n",
            "Node id: 389, hubbiness score: 0.863417110184379\n",
            "Node id: 472, hubbiness score: 0.8632841092495217\n",
            "\n",
            "\n",
            "\n",
            "The 5 node ids with the lowest hubbiness scores:\n",
            "Node id: 23, hubbiness score: 0.042066854890936534\n",
            "Node id: 835, hubbiness score: 0.05779059354433016\n",
            "Node id: 141, hubbiness score: 0.06453117646225179\n",
            "Node id: 539, hubbiness score: 0.06602659373418492\n",
            "Node id: 889, hubbiness score: 0.07678413939216454\n",
            "\n",
            "\n",
            "\n",
            "The 5 node ids with the highest authority scores:\n",
            "Node id: 893, hubbiness score: 1.0\n",
            "Node id: 16, hubbiness score: 0.9635572849634398\n",
            "Node id: 799, hubbiness score: 0.9510158161074016\n",
            "Node id: 146, hubbiness score: 0.9246703586198444\n",
            "Node id: 473, hubbiness score: 0.899866197360405\n",
            "\n",
            "\n",
            "\n",
            "The 5 node ids with the lowest authority scores:\n",
            "Node id: 19, hubbiness score: 0.05608316377607618\n",
            "Node id: 135, hubbiness score: 0.06653910487622794\n",
            "Node id: 462, hubbiness score: 0.07544228624641902\n",
            "Node id: 24, hubbiness score: 0.08171239406816946\n",
            "Node id: 910, hubbiness score: 0.08571673456144878\n",
            "\n",
            "\n",
            "\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ET5doifWehWG",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        ""
      ],
      "execution_count": 0,
      "outputs": []
    }
  ]
}